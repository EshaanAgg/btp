{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers\n",
    "\n",
    "This notebook will focus on the implementation on a customizable model from scratch on the `Tweets` dataset for classification purposes. \n",
    "\n",
    "## Without Transformer's Module\n",
    "\n",
    "We will be following the architecture from the original paper [Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf?ref=blog.paperspace.com), with primarily the help of `Keras` and `Tensorflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the needed modules\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout, Layer\n",
    "from tensorflow.keras.layers import Embedding, Input, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Block\n",
    "\n",
    "This represents one of the blocks in the Transformer architecture. We will the following kinds of layers in this block:\n",
    "\n",
    "1. We use the `MultiHeadAttention` provided by `Tensorflow` directly to avoid the implementation of the following steps:\n",
    "- Split the `K`, `V` and `Q` vectors with dimension `embed_dim` into the required vectors based on the number of heads.\n",
    "- Apply a linear layer to each of them.\n",
    "- Perform a Scaled Dot Product to calculate the value for each of them.\n",
    "- Concat all the vectors and then apply a linear classifier on it.\n",
    "- Apply addition and normalization to the inputs.\n",
    "\n",
    "1. A `Feed Forward Neural Network` that accepts the number of number of neuros `ff_dim` and the embedding dimension `embed_dim` and genrates a simple `Sequential` layer.\n",
    "\n",
    "2. A `Normalization` layer to normalize the activations of the previous layer. \n",
    "3. A `Dropout` layer to randomly set input units to 0 with a frequency of `rate` at each step during training time, which helps prevent overfitting. Inputs not set to 0 are scaled up by 1 / (1 - rate) such that the sum over all inputs is unchanged. This ensures that the layer stays normalized.\n",
    "\n",
    "We do not apply a `Masked Multi Attention Head` layer in our implementation as we are going to be using this transformer for classification and not for generation. Thus we do not need to mask the next words in our input. Also due to the nature of the classification task, we do not need seperate `Encoder` and `Decoder` blocks, as now the architecture of both of them would overlap greatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attentionLayer = MultiHeadAttention(\n",
    "            num_heads=num_heads, \n",
    "            key_dim=embed_dim\n",
    "        )\n",
    "        self.feedForwardNN = Sequential(\n",
    "            [\n",
    "                Dense(ff_dim, activation=\"relu\"),\n",
    "                Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.normalization1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.normalization2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    # inputs: Matrix of the appropiate size\n",
    "    # training: Boolean to represent the model is being used in training or prediction\n",
    "    def call(self, inputs, training):\n",
    "        # Query = Value = Key = inputs\n",
    "        # Key = Value is the most common case\n",
    "        attn_output = self.attentionLayer(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        # out1 is the initial result after applying the attention layer and needs to be concatenated with the FFN\n",
    "        out1 = self.normalization1(inputs + attn_output)\n",
    "\n",
    "        ffn_output = self.feedForwardNN(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.normalization2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Blocks\n",
    "\n",
    "Using this block, we would create two embedding layers, namely for the `tokens` and the `token index positions`. \n",
    "1. In the first layer, we initialize the token embeddings from the `vocab` to a space of `embed_dim` dimensions.\n",
    "2. In the next layer, we intiliaze the positional embeddings. The input dimension would obviously be the length of the sequence and the output dimension would be same as `embed_dim`.\n",
    "\n",
    "For this layer, it is assumed that all the inputs have been padded to the fixed length `maxlen`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        maxlen = tf.shape(inputs)[-1]\n",
    "        # positions = [0, 1, 2, ....., maxlen -1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "\n",
    "        inputs = self.token_emb(inputs)\n",
    "        return inputs + positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data and Building the Model\n",
    "\n",
    "The following code does the following:\n",
    "- Load the dataset and split it into a `1:3` testing-training dataset.\n",
    "- Map all the words to a distinct index (from `1` to `vocab_size`) \n",
    "- Pad all the tweets to `maxlen` to make them of the same length. \n",
    "\n",
    "In the next block, we put together the model with the following layers:\n",
    "- Embedding Layer (Word + Positional)\n",
    "- Transformer Block (MultiHead Attention + Feed Forward Neural Network)\n",
    "- `AveragePooling` layer\n",
    "- `Dropout` layer\n",
    "- `Dense` Layer for classification followed by another `Dropout` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"data/sample_tweets.csv\", sep=\",\", names=[\"label\", \"text\"], header=0)\n",
    "tweets = df[\"text\"].values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Divide into a 25% test set and 75% training set\n",
    "tweets_train, tweets_test, y_train, y_test = train_test_split(\n",
    "    tweets, y, test_size=0.25, random_state=1000\n",
    ")\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=2500)\n",
    "tokenizer.fit_on_texts(tweets_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(tweets_train)\n",
    "X_test = tokenizer.texts_to_sequences(tweets_test)\n",
    "\n",
    "vocab_size = (\n",
    "    len(tokenizer.word_index) + 1\n",
    ")  # Adding 1 because of reserved 0 index for padding\n",
    "\n",
    "\n",
    "maxlen = 100\n",
    "X_train = pad_sequences(X_train, padding=\"post\", maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding=\"post\", maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 32      # Embedding size for each token\n",
    "num_heads = 2       # Number of attention heads\n",
    "ff_dim = 32         # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "inputs = Input(shape=(maxlen,))\n",
    "embedding_layer = TokenAndPositionEmbedding(\n",
    "    maxlen, \n",
    "    vocab_size, \n",
    "    embed_dim\n",
    ")\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(\n",
    "    embed_dim, \n",
    "    num_heads, \n",
    "    ff_dim\n",
    ")\n",
    "x = transformer_block(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(20, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "outputs = Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation and Evaluation of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 1s 48ms/step - loss: 0.7461 - accuracy: 0.5173 - val_loss: 0.5840 - val_accuracy: 0.7200\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6524 - accuracy: 0.6667 - val_loss: 0.5754 - val_accuracy: 0.7200\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6404 - accuracy: 0.6507 - val_loss: 0.6102 - val_accuracy: 0.7200\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6085 - accuracy: 0.6773 - val_loss: 0.5699 - val_accuracy: 0.7200\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5790 - accuracy: 0.6853 - val_loss: 0.5439 - val_accuracy: 0.7200\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.5445 - accuracy: 0.7013 - val_loss: 0.5371 - val_accuracy: 0.7280\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5305 - accuracy: 0.7573 - val_loss: 0.5160 - val_accuracy: 0.7280\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.4880 - accuracy: 0.7653 - val_loss: 0.4854 - val_accuracy: 0.7440\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.4230 - accuracy: 0.8133 - val_loss: 0.4672 - val_accuracy: 0.8240\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.3906 - accuracy: 0.8640 - val_loss: 0.4518 - val_accuracy: 0.7440\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.3375 - accuracy: 0.9200 - val_loss: 0.4531 - val_accuracy: 0.7520\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3521 - accuracy: 0.8507 - val_loss: 0.5547 - val_accuracy: 0.7040\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.2813 - accuracy: 0.8987 - val_loss: 0.3756 - val_accuracy: 0.8240\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.2095 - accuracy: 0.9707 - val_loss: 0.3143 - val_accuracy: 0.9120\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.1527 - accuracy: 0.9733 - val_loss: 0.2848 - val_accuracy: 0.9280\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.1053 - accuracy: 0.9920 - val_loss: 0.2695 - val_accuracy: 0.9120\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0725 - accuracy: 1.0000 - val_loss: 0.2703 - val_accuracy: 0.8720\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9120\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.2290 - val_accuracy: 0.9200\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9360\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9280\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9440\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.2840 - val_accuracy: 0.9200\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9280\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.9360\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3267 - val_accuracy: 0.9200\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3064 - val_accuracy: 0.9440\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2767 - val_accuracy: 0.9280\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9280\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3037 - val_accuracy: 0.9360\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 7.7955e-04 - accuracy: 1.0000 - val_loss: 0.3263 - val_accuracy: 0.9360\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.6552e-04 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9440\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.5485e-04 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 0.9440\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.5541e-04 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9360\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.0766e-04 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9360\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.2823e-04 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.9360\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.4197e-04 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9360\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.7369e-04 - accuracy: 1.0000 - val_loss: 0.3495 - val_accuracy: 0.9360\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.9363e-04 - accuracy: 1.0000 - val_loss: 0.3535 - val_accuracy: 0.9360\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.2441e-04 - accuracy: 1.0000 - val_loss: 0.3492 - val_accuracy: 0.9360\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.2455e-04 - accuracy: 1.0000 - val_loss: 0.3570 - val_accuracy: 0.9360\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.2928e-04 - accuracy: 1.0000 - val_loss: 0.3480 - val_accuracy: 0.9360\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.4792e-04 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.9360\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.8101e-04 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9360\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.4514e-04 - accuracy: 1.0000 - val_loss: 0.3372 - val_accuracy: 0.9360\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.5584e-04 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 0.9200\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.7428e-04 - accuracy: 1.0000 - val_loss: 0.3211 - val_accuracy: 0.9280\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.8437e-04 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9440\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.9870e-04 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.9200\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.4040e-04 - accuracy: 1.0000 - val_loss: 0.4429 - val_accuracy: 0.9200\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4/4 - 0s - loss: 0.4429 - accuracy: 0.9200 - 29ms/epoch - 7ms/step\n",
      "loss: 0.443\n",
      "accuracy: 0.920\n"
     ]
    }
   ],
   "source": [
    "# Compile and train the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    validation_data=(X_test, y_test),\n",
    ")\n",
    "\n",
    "# Save the weights of the model\n",
    "model.save_weights(\"data/training_checkpoints/transformer1.h5\")\n",
    "\n",
    "# Evaluate the model on the testing data and print the results\n",
    "print(\"\\n\\n\\n\")\n",
    "results = model.evaluate(X_test, y_test, verbose=2)\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(\"%s: %.3f\" % (name, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
